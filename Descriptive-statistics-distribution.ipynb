{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Copyright 2021 Andrew M. Olney and made available under [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0) for text and [Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0) for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics: distribution-based metrics\n",
    "\n",
    "We can also consider descriptive statistics based on the distribution of words.\n",
    "Distribution in this sense means an assignment of numbers to each word, like the frequency of each word or the probability of each word in the corpus.\n",
    "The methods that we will discuss consider the *identity* of each word, which we ignored when we looked at length-based metrics.\n",
    "The key idea in this notebook is that we can **transform text into a distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will learn\n",
    "\n",
    "You will learn about text-oriented descriptive statistics derived based on distributions of text.\n",
    "  \n",
    "We will cover:\n",
    "\n",
    "- Distribution-based metrics\n",
    "    - Lexical diversity\n",
    "    - Frequency distributions\n",
    "    - Conditional distributions\n",
    "    - Vectorization\n",
    "    - tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use distribution-based metrics\n",
    "\n",
    "Descriptive statistics are helpful for exploring the data and considering other potential analyses.\n",
    "The transformations on text that we discuss may also be useful as features in later modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-based metrics\n",
    "\n",
    "We'll use the built-in `brown` corpus from NLTK.\n",
    "Let's import the `brown` corpus and `nltk`:\n",
    "\n",
    "- from `nltk.corpus` import `brown`\n",
    "- import `nltk` as `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk as nltk\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable><variable id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</variable></variables><block type=\"importFrom\" id=\"XD9YVa/m9vX;ax-@^}(K\" x=\"16\" y=\"64\"><field name=\"libraryName\">nltk.corpus</field><field name=\"libraryAlias\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><next><block type=\"importAs\" id=\"rek|J;Kp}vn71.HIYns.\"><field name=\"libraryName\">nltk</field><field name=\"libraryAlias\" id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</field></block></next></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus) is a diverse corpus of 500 texts collected in 1961 from 15 genres, e.g. news, fiction, religion, and biographies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical diversity\n",
    "\n",
    "Before we continue, it is important to make the distinction between a word `type` and a word `token`.\n",
    "\n",
    "A token is a single instance of a word. If I say \"love love love,\" then there are three tokens, or three instances of \"love.\"\n",
    "A type is a category. So if I say \"love love love,\" there is only one type. If I say \"love like love,\" there are two types.\n",
    "\n",
    "The way to get the number of types from a list of tokens is to remove duplicates.\n",
    "So to get the number of tokens in a list, we can use the length of the list (in category LIST)\n",
    "To get the number of types in a list, we need to remove duplicates and then get the length. \n",
    "We can remove duplicates with something called `set` (also in LIST).\n",
    "\n",
    "Let's start by calculating the number of tokens in `brown`:\n",
    "\n",
    "- length of with `brown` do `words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"lists_length\" id=\"^2]p$ss.Y@kU=B#X1pwI\" x=\"35\" y=\"201\"><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"Z^i#2h_%c^%13-CP8*3c\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now count the tokens using `set`:\n",
    "\n",
    "- length of set with `brown` do `words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56057"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(brown.words()))\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"lists_length\" id=\"^2]p$ss.Y@kU=B#X1pwI\" x=\"35\" y=\"201\"><value name=\"VALUE\"><block type=\"setBlock\" id=\"a8Ol:lYH4:@|ge)})UkC\"><value name=\"x\"><block type=\"varDoMethod\" id=\"Z^i#2h_%c^%13-CP8*3c\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty huge difference! \n",
    "Even in a very diverse corpus of over a million words, there are only just over 56 thousand distinct word forms - and this includes inflections, so the true number of types is even smaller!\n",
    "\n",
    "**An important fact about language is that most words are rare.**\n",
    "\n",
    "Type/token ratio is perhaps the most famous measure of lexical diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distributions\n",
    "\n",
    "We can see most words are rare by looking at the frequency distribution of words in a text. \n",
    "A small group of words, starting with articles and prepositions, will make up most of the tokens.\n",
    "\n",
    "NLTK has a built in function for calculating frequency distributions from words called `FreqDist` that takes word tokens as input:\n",
    "\n",
    "- Set `freqDist` to with `nltk` create `FreqDist` using with `brown` do `words` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDist = nltk.FreqDist(brown.words())\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable><variable id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</variable><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"variables_set\" id=\"|h8;O9TR1_A8}Xp]fW-C\" x=\"40\" y=\"192\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><value name=\"VALUE\"><block type=\"varCreateObject\" id=\"MF_C[_R/Y,btk]v=cjzp\"><field name=\"VAR\" id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</field><field name=\"MEMBER\">FreqDist</field><data>nltk:FreqDist</data><value name=\"INPUT\"><block type=\"varDoMethod\" id=\"kV/2vdy=,0[QxDto6QJL\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than showing a frequency distribution for all words in `brown`, which would fill up our notebook, we'll ask for only the top 50:\n",
    "\n",
    "- with `freqDist` do `most_common` using `50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011), ('was', 9777), ('for', 8841), ('``', 8837), (\"''\", 8789), ('The', 7258), ('with', 7012), ('it', 6723), ('as', 6706), ('he', 6566), ('his', 6466), ('on', 6395), ('be', 6344), (';', 5566), ('I', 5161), ('by', 5103), ('had', 5102), ('at', 4963), ('?', 4693), ('not', 4423), ('are', 4333), ('from', 4207), ('or', 4118), ('this', 3966), ('have', 3892), ('an', 3542), ('which', 3540), ('--', 3432), ('were', 3279), ('but', 3007), ('He', 2982), ('her', 2885), ('one', 2873), ('they', 2773), ('you', 2766), ('all', 2726), ('would', 2677), ('him', 2576), ('their', 2562), ('been', 2470), (')', 2466)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist.most_common(50)\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable></variables><block type=\"varDoMethod\" id=\"iBVXyNhV;n,nYitk()4W\" x=\"8\" y=\"161\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><field name=\"MEMBER\">most_common</field><data>freqDist:most_common</data><value name=\"INPUT\"><block type=\"math_number\" id=\"h=^uH@Mnt7$jT4:VKS2W\"><field name=\"NUM\">50</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, most words are [function words](https://en.wikipedia.org/wiki/Function_word) and punctuation.\n",
    "\n",
    "**This illustrates that just because a word is frequent, that doesn't mean the word is important.**\n",
    "\n",
    "We can also check out how many words occur only once; in NLTK and linguistics, these are known as [hapax legomenon](https://en.wikipedia.org/wiki/Hapax_legomenon):\n",
    "\n",
    "- Set `hapaxes` to with `freqDist` do `hapaxes`\n",
    "- Display length of `hapaxes`\n",
    "\n",
    "*Note: We don't need to use `set` with `length` because each hapax is unique by definition (tokens=types)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25559"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes = freqDist.hapaxes()\n",
    "\n",
    "len(hapaxes)\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</variable><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable></variables><block type=\"variables_set\" id=\")8|]9J.@_(k#D7E~.EJB\" x=\"7\" y=\"276\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"iBVXyNhV;n,nYitk()4W\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><field name=\"MEMBER\">hapaxes</field><data>freqDist:hapaxes</data></block></value></block><block type=\"lists_length\" id=\"1EmU}e~7{S}y33k%o;eM\" x=\"11\" y=\"351\"><value name=\"VALUE\"><block type=\"variables_get\" id=\"4fMC1BftF)!-8~E5/~2(\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Almost half of the words in `brown` only occur once!**\n",
    "\n",
    "Let's look at 50 of them:\n",
    "\n",
    "- in list `hapaxes` get sub-list from `first` to `50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term-end', 'presentments', 'September-October', 'Durwood', 'Pye', 'Mayor-nominate', 'Merger', 're-set', 'disable', \"ordinary's\", 'appraisers', 'Wards', 'juries', 'unmeritorious', 'Regarding', 'extern', \"Commissioner's\", 'Bellwood', 'Alpharetta', 'Cheshire', 'amicable', '637', 'expires', 'Dorsey', 'Tower', 'Ledford', 'Gainesville', 'Schley', '87-31', '29-5', 'Mac', '1,119', '402', 'calmest', 'Policeman', 'Callan', 'Tabb', \"Daniel's\", 'Legislatures', 'erase', 'depositors', 'Gaynor', 'Brady', 'Harlingen', 'Deaf', 'Bexar', 'Tarrant', '$451,500', '$157,460', '$88,000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes[ : 50]\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</variable></variables><block type=\"lists_getSublist\" id=\"9xn$*AOGa:EQ*Dc,*!43\" x=\"55\" y=\"244\"><mutation at1=\"false\" at2=\"true\"></mutation><field name=\"WHERE1\">FIRST</field><field name=\"WHERE2\">FROM_START</field><value name=\"LIST\"><block type=\"variables_get\" id=\"bk_U%Y.KPnZ:vC9_me^X\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field></block></value><value name=\"AT2\"><block type=\"math_number\" id=\"f`ceI1r6(p/hz!Su9Vp5\"><field name=\"NUM\">50</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these rare words look like they might be important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional distributions\n",
    "\n",
    "We just calculated `FreqDist` using the entire corpus, but what if we wanted to calculate `FreqDist` for different texts or collections of text and compare them?\n",
    "\n",
    "To do that, we can use `ConditionalFreqDist`, which let's us assign words to a *sample* and then calculate `FreqDist`s for all samples.\n",
    "A good illustration of this comes directly from the NLTK book using the `brown` corpus, where each text has already been assigned to a *category*.\n",
    "We will consider each category as a sample.\n",
    "\n",
    "Let's start by looking at the categories:\n",
    "\n",
    "- with `brown` do `categories`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"varDoMethod\" id=\"SyBO)HDnfWp@N,$zyD9a\" x=\"8\" y=\"188\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">categories</field><data>brown:categories</data></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use these categories to assign each word to a sample, we'll create a list of tuples `(category,word)` using a nested comprehension:\n",
    "\n",
    "- Set `sampleList` to a list with one element for each item `word` in list\n",
    "    - with `brown` do `words`\n",
    "    - yield for each item `genre` in list\n",
    "        - with `brown` do `categories`\n",
    "        - yield (`genre`,`word`)\n",
    "- in list `sampleList` get sub-list `first` to `5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('adventure', 'Dan'), ('adventure', 'Morgan'), ('adventure', 'told'), ('adventure', 'himself'), ('adventure', 'he')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleList = [((genre,word)) for genre in (brown.categories()) for word in (brown.words(categories=genre))]\n",
    "\n",
    "sampleList[ : 5]\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"[z3kRetk8}byrFOPrO/4\">sampleList</variable><variable id=\"c|WH1pZH%^rWv9G-!to~\">word</variable><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable><variable id=\"Q^e2o,)4G7S6RN^FWc`s\">genre</variable></variables><block type=\"variables_set\" id=\"=+xjD^O_/{W^:lnksD{6\" x=\"31\" y=\"54\"><field name=\"VAR\" id=\"[z3kRetk8}byrFOPrO/4\">sampleList</field><value name=\"VALUE\"><block type=\"lists_create_with\" id=\"z*aKGdDmf#$O:GhZh)~y\"><mutation items=\"1\"></mutation><value name=\"ADD0\"><block type=\"comprehensionForEach\" id=\"g1:^IIk;f4b/g5%c}EQu\"><field name=\"VAR\" id=\"c|WH1pZH%^rWv9G-!to~\">word</field><value name=\"LIST\"><block type=\"varDoMethod\" id=\"=,BF(@XhpGc?ywvd?ZK,\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data><value name=\"INPUT\"><block type=\"dummyOutputCodeBlock\" id=\"kKc6EQ(,]BFjb|Q7B|Al\"><field name=\"CODE\">categories=genre</field></block></value></block></value><value name=\"YIELD\"><block type=\"comprehensionForEach\" id=\"yX!)#xp]4*q?E%wpiSIS\"><field name=\"VAR\" id=\"Q^e2o,)4G7S6RN^FWc`s\">genre</field><value name=\"LIST\"><block type=\"varDoMethod\" id=\"(jZmm#T-1gqff(AUJqoO\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">categories</field><data>brown:categories</data></block></value><value name=\"YIELD\"><block type=\"tupleBlock\" id=\"J|r1{P[K@rlMBd9Dc^bX\"><value name=\"FIRST\"><block type=\"variables_get\" id=\"VZ7^vn`GF$Boo.E1(}(b\"><field name=\"VAR\" id=\"Q^e2o,)4G7S6RN^FWc`s\">genre</field></block></value><value name=\"SECOND\"><block type=\"variables_get\" id=\"4FxP71A^,oP~O2S#h;Sz\"><field name=\"VAR\" id=\"c|WH1pZH%^rWv9G-!to~\">word</field></block></value></block></value></block></value></block></value></block></value></block><block type=\"lists_getSublist\" id=\"Sr=L=Ef%^lF#_:19-p[z\" x=\"30\" y=\"184\"><mutation at1=\"false\" at2=\"true\"></mutation><field name=\"WHERE1\">FIRST</field><field name=\"WHERE2\">FROM_START</field><value name=\"LIST\"><block type=\"variables_get\" id=\"xFQbGi%ghPsTOy6T4_[(\"><field name=\"VAR\" id=\"[z3kRetk8}byrFOPrO/4\">sampleList</field></block></value><value name=\"AT2\"><block type=\"math_number\" id=\"c_MRih.]!Y3`tMd;{j1v\"><field name=\"NUM\">5</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a `ConditionalFreqDist` using the `sampleList`:\n",
    "\n",
    "- Set `condFreqDist` to with `nltk` create `ConditionalFreqDist` using `sampleList`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "condFreqDist = nltk.ConditionalFreqDist(sampleList)\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</variable><variable id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</variable><variable id=\"[z3kRetk8}byrFOPrO/4\">sampleList</variable></variables><block type=\"variables_set\" id=\"(RV:LLl3YGFa]HN:scW3\" x=\"15\" y=\"223\"><field name=\"VAR\" id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</field><value name=\"VALUE\"><block type=\"varCreateObject\" id=\"L2hl.JRkkl[GUF}CDR,y\"><field name=\"VAR\" id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</field><field name=\"MEMBER\">ConditionalFreqDist</field><data>nltk:ConditionalFreqDist</data><value name=\"INPUT\"><block type=\"variables_get\" id=\"j%Y}!Of5;0ukeH(-NMtT\"><field name=\"VAR\" id=\"[z3kRetk8}byrFOPrO/4\">sampleList</field></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`condFreqDist` has a `FreqDist` for each sample, so we can operate on those individually.\n",
    "However, each was constructed independently of the other, so they contain different words:\n",
    "\n",
    "- print length of `condFreqDist`[\"fiction\"]\n",
    "- print length of `condFreqDist`[\"fiction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9302\n",
      "14394\n"
     ]
    }
   ],
   "source": [
    "print(len(condFreqDist['fiction']))\n",
    "print(len(condFreqDist['news']))\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</variable></variables><block type=\"text_print\" id=\"ZwYX5^!J%u$?rMA.C(km\" x=\"-15\" y=\"263\"><value name=\"TEXT\"><shadow type=\"text\" id=\"8k(q;IilTA^c`vsfuO#4\"><field name=\"TEXT\">abc</field></shadow><block type=\"lists_length\" id=\"~GDW+QTtSo.1;=`^j-:_\"><value name=\"VALUE\"><block type=\"indexer\" id=\"]0YdtHCx7w-/g0o{#3MA\"><field name=\"VAR\" id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</field><value name=\"INDEX\"><block type=\"text\" id=\"@j=OUHL6h.o=hu|NX)bi\"><field name=\"TEXT\">fiction</field></block></value></block></value></block></value><next><block type=\"text_print\" id=\"u.]I_X$VX?IcQH.aB`LM\"><value name=\"TEXT\"><shadow type=\"text\"><field name=\"TEXT\">abc</field></shadow><block type=\"lists_length\" id=\"YJX[Rpn}Kc9!Y:yHO+ZS\"><value name=\"VALUE\"><block type=\"indexer\" id=\"q#|YV|wlsGwp}xgnhC1a\"><field name=\"VAR\" id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</field><value name=\"INDEX\"><block type=\"text\" id=\"F,V]`glY5bl9#r%~wd[2\"><field name=\"TEXT\">news</field></block></value></block></value></block></value></block></next></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is possible to [compare the FreqDists to each other and perform other operations with them](https://www.nltk.org/howto/probability.html?highlight=conditionalfreqdist), it can be convenient to get a count of words across all of them for a specific set of words.\n",
    "Let's take a look at this for modal verbs:\n",
    "\n",
    "- with `condFreqDist` do `tabulate` using a list containing\n",
    "    - freestyle `conditions=` with `brown` do `categorie`\n",
    "    - freestyle `samples=` make `list from text` `\"can,could,will,would,shall,should,may,might,must\"` with delimiter `\",\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   can  could   will  would  shall should    may  might   must \n",
      "      adventure     46    151     50    191      7     15      5     58     27 \n",
      " belles_lettres    246    213    236    392     34    102    207    113    170 \n",
      "      editorial    121     56    233    180     19     88     74     39     53 \n",
      "        fiction     37    166     52    287      3     35      8     44     55 \n",
      "     government    117     38    244    120     98    112    153     13    102 \n",
      "        hobbies    268     58    264     78      5     73    131     22     83 \n",
      "          humor     16     30     13     56      2      7      8      8      9 \n",
      "        learned    365    159    340    319     40    171    324    128    202 \n",
      "           lore    170    141    175    186     12     76    165     49     96 \n",
      "        mystery     42    141     20    186      1     29     13     57     30 \n",
      "           news     93     86    389    244      5     59     66     38     50 \n",
      "       religion     82     59     71     68     21     45     78     12     54 \n",
      "        reviews     45     40     58     47      1     18     45     26     19 \n",
      "        romance     74    193     43    244      3     32     11     51     45 \n",
      "science_fiction     16     49     16     79      3      3      4     12      8 \n"
     ]
    }
   ],
   "source": [
    "condFreqDist.tabulate(conditions= (brown.categories()), samples= ('can,could,will,would,shall,should,may,might,must'.split(',')))\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</variable><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"varDoMethod\" id=\"KHjR:zM}05.Lc/@mzmGN\" x=\"-20\" y=\"188\"><field name=\"VAR\" id=\"~,iPkj0(XtQzVgbkwsSQ\">condFreqDist</field><field name=\"MEMBER\">tabulate</field><data>condFreqDist:tabulate</data><value name=\"INPUT\"><block type=\"lists_create_with\" id=\":VdN{%m#NoYGO(O]93zU\"><mutation items=\"2\"></mutation><value name=\"ADD0\"><block type=\"valueOutputCodeBlock\" id=\"~]IR$V~UMX%mLSwvCK;8\"><field name=\"CODE\">conditions=</field><value name=\"INPUT\"><block type=\"varDoMethod\" id=\"sh?ls]sB-wrRgRbnV~xt\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">categories</field><data>brown:categories</data></block></value></block></value><value name=\"ADD1\"><block type=\"valueOutputCodeBlock\" id=\"]y/JNoD=osOPJ|IA$8H{\"><field name=\"CODE\">samples=</field><value name=\"INPUT\"><block type=\"lists_split\" id=\"Mgs^[ZjC~Ucc|eNV64FM\"><mutation mode=\"SPLIT\"></mutation><field name=\"MODE\">SPLIT</field><value name=\"INPUT\"><block type=\"text\" id=\"KDhf]yrN@djv;YpC+Y)Z\"><field name=\"TEXT\">can,could,will,would,shall,should,may,might,must</field></block></value><value name=\"DELIM\"><shadow type=\"text\" id=\"`AJqgOQ;?tDjYmN2?`?!\"><field name=\"TEXT\">,</field></shadow></value></block></value></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think about this tabulation both descriptively and from a text transformation perspective.\n",
    "If we are specifically interested in modal verbs, then these columns represent variables of interest in the text, and each entry represents a measurement on that variable.\n",
    "\n",
    "However, we can imagine that if we had even more columns, especially if we have a column for every word, we have now transformed the texts in a way that is less useful descriptively (because there is so much to look at) but useful in a different way as a pure transformation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
