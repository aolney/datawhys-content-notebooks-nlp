{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Copyright 2021 Andrew M. Olney and made available under [CC BY-SA](https://creativecommons.org/licenses/by-sa/4.0) for text and [Apache-2.0](http://www.apache.org/licenses/LICENSE-2.0) for code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics: distribution-based metrics\n",
    "\n",
    "We can also consider descriptive statistics based on the distribution of words.\n",
    "Distribution in this sense means an assignment of numbers to each word, like the frequency of each word or the probability of each word in the corpus.\n",
    "The methods that we will discuss consider the *identity* of each word, which we ignored when we looked at length-based metrics.\n",
    "The key idea in this notebook is that we can **transform text into a distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will learn\n",
    "\n",
    "You will learn about text-oriented descriptive statistics derived based on distributions of text.\n",
    "  \n",
    "We will cover:\n",
    "\n",
    "- Distribution-based metrics\n",
    "    - Lexical diversity\n",
    "    - Frequency distributions\n",
    "    - Conditional distributions\n",
    "    - Vectorization\n",
    "    - tf-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use distribution-based metrics\n",
    "\n",
    "Descriptive statistics are helpful for exploring the data and considering other potential analyses.\n",
    "The transformations on text that we discuss may also be useful as features in later modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-based metrics\n",
    "\n",
    "We'll use the built-in `brown` corpus from NLTK.\n",
    "Let's import the `brown` corpus and `nltk`:\n",
    "\n",
    "- from `nltk.corpus` import `brown`\n",
    "- import `nltk` as `nltk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "import nltk as nltk\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable><variable id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</variable></variables><block type=\"importFrom\" id=\"XD9YVa/m9vX;ax-@^}(K\" x=\"16\" y=\"64\"><field name=\"libraryName\">nltk.corpus</field><field name=\"libraryAlias\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><next><block type=\"importAs\" id=\"rek|J;Kp}vn71.HIYns.\"><field name=\"libraryName\">nltk</field><field name=\"libraryAlias\" id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</field></block></next></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Brown Corpus](https://en.wikipedia.org/wiki/Brown_Corpus) is a diverse corpus of 500 texts collected in 1961 from 15 genres, e.g. news, fiction, religion, and biographies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexical diversity\n",
    "\n",
    "Before we continue, it is important to make the distinction between a word `type` and a word `token`.\n",
    "\n",
    "A token is a single instance of a word. If I say \"love love love,\" then there are three tokens, or three instances of \"love.\"\n",
    "\n",
    "A type is a category. So if I say \"love love love,\" there is only one type. If I say \"love like love,\" there are two types.\n",
    "\n",
    "The way to get the number of types from a list of tokens is to remove duplicates.\n",
    "\n",
    "So to get the number of tokens in a list, we can use the length of the list (in category LIST)\n",
    "\n",
    "To get the number of types in a list, we need to remove duplicates and then get the length. \n",
    "\n",
    "We can remove duplicates with something called `set` (also in LIST).\n",
    "\n",
    "Let's start by calculating the number of tokens in `brown`:\n",
    "\n",
    "- length of with `brown` do `words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brown.words())\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"lists_length\" id=\"^2]p$ss.Y@kU=B#X1pwI\" x=\"35\" y=\"201\"><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"Z^i#2h_%c^%13-CP8*3c\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now count the tokens using `set`:\n",
    "\n",
    "- length of set with `brown` do `words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56057"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(brown.words()))\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"lists_length\" id=\"^2]p$ss.Y@kU=B#X1pwI\" x=\"35\" y=\"201\"><value name=\"VALUE\"><block type=\"setBlock\" id=\"a8Ol:lYH4:@|ge)})UkC\"><value name=\"x\"><block type=\"varDoMethod\" id=\"Z^i#2h_%c^%13-CP8*3c\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty huge difference! \n",
    "Even in a very diverse corpus of over a million words, there are only just over 56 thousand distinct word forms - and this includes inflections, so the truth is even smaller!\n",
    "\n",
    "**An important fact about language is that most words are rare.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distributions\n",
    "\n",
    "We can see most words are rare by looking at the \"frequency distribution\" of words in a text. \n",
    "A small group of words, starting with articles and prepositions, will make up most of the tokens.\n",
    "\n",
    "NLTK has a built in function for calculating frequency distributions from words:\n",
    "\n",
    "- Set `freqDist` to with `nltk` create `FreqDist` using with `brown` do `words` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDist = nltk.FreqDist(brown.words())\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable><variable id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</variable><variable id=\"NI3uGxsG=?2gcS,ewPW!\">brown</variable></variables><block type=\"variables_set\" id=\"|h8;O9TR1_A8}Xp]fW-C\" x=\"40\" y=\"192\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><value name=\"VALUE\"><block type=\"varCreateObject\" id=\"MF_C[_R/Y,btk]v=cjzp\"><field name=\"VAR\" id=\"Wer,Q4C`j@I;1xVaLJBR\">nltk</field><field name=\"MEMBER\">FreqDist</field><data>nltk:FreqDist</data><value name=\"INPUT\"><block type=\"varDoMethod\" id=\"kV/2vdy=,0[QxDto6QJL\"><field name=\"VAR\" id=\"NI3uGxsG=?2gcS,ewPW!\">brown</field><field name=\"MEMBER\">words</field><data>brown:words</data></block></value></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than showing a frequency distribution for all words in `brown`, which would fill up our notebook, we'll ask for only the top 50:\n",
    "\n",
    "- with `freqDist` do `most_common` using `50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713), (',', 58334), ('.', 49346), ('of', 36080), ('and', 27915), ('to', 25732), ('a', 21881), ('in', 19536), ('that', 10237), ('is', 10011), ('was', 9777), ('for', 8841), ('``', 8837), (\"''\", 8789), ('The', 7258), ('with', 7012), ('it', 6723), ('as', 6706), ('he', 6566), ('his', 6466), ('on', 6395), ('be', 6344), (';', 5566), ('I', 5161), ('by', 5103), ('had', 5102), ('at', 4963), ('?', 4693), ('not', 4423), ('are', 4333), ('from', 4207), ('or', 4118), ('this', 3966), ('have', 3892), ('an', 3542), ('which', 3540), ('--', 3432), ('were', 3279), ('but', 3007), ('He', 2982), ('her', 2885), ('one', 2873), ('they', 2773), ('you', 2766), ('all', 2726), ('would', 2677), ('him', 2576), ('their', 2562), ('been', 2470), (')', 2466)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqDist.most_common(50)\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable></variables><block type=\"varDoMethod\" id=\"iBVXyNhV;n,nYitk()4W\" x=\"8\" y=\"161\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><field name=\"MEMBER\">most_common</field><data>freqDist:most_common</data><value name=\"INPUT\"><block type=\"math_number\" id=\"h=^uH@Mnt7$jT4:VKS2W\"><field name=\"NUM\">50</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, most words are [function words](https://en.wikipedia.org/wiki/Function_word) and punctuation.\n",
    "\n",
    "**This illustrates that just because a word is frequent, that doesn't mean the word is important.**\n",
    "\n",
    "We can also check out how many words occur only once; in NLTK and linguistics, these are known as [hapax legomenon](https://en.wikipedia.org/wiki/Hapax_legomenon):\n",
    "\n",
    "- Set `hapaxes` to with `freqDist` do `hapaxes`\n",
    "- length of `hapaxes`\n",
    "\n",
    "*Note: We don't need to use `set` with `length` because each hapax is unique by definition (tokens=types)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25559"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes = freqDist.hapaxes()\n",
    "\n",
    "len(hapaxes)\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</variable><variable id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</variable></variables><block type=\"variables_set\" id=\")8|]9J.@_(k#D7E~.EJB\" x=\"7\" y=\"276\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"iBVXyNhV;n,nYitk()4W\"><field name=\"VAR\" id=\"ODvNsyro,)$TD)6LqB`r\">freqDist</field><field name=\"MEMBER\">hapaxes</field><data>freqDist:hapaxes</data></block></value></block><block type=\"lists_length\" id=\"1EmU}e~7{S}y33k%o;eM\" x=\"11\" y=\"351\"><value name=\"VALUE\"><block type=\"variables_get\" id=\"4fMC1BftF)!-8~E5/~2(\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that almost half of the words in `brown` only occur once!\n",
    "\n",
    "Let's look at 50 of them:\n",
    "\n",
    "- in list `hapaxes` get sub-list from `first` to `50`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term-end', 'presentments', 'September-October', 'Durwood', 'Pye', 'Mayor-nominate', 'Merger', 're-set', 'disable', \"ordinary's\", 'appraisers', 'Wards', 'juries', 'unmeritorious', 'Regarding', 'extern', \"Commissioner's\", 'Bellwood', 'Alpharetta', 'Cheshire', 'amicable', '637', 'expires', 'Dorsey', 'Tower', 'Ledford', 'Gainesville', 'Schley', '87-31', '29-5', 'Mac', '1,119', '402', 'calmest', 'Policeman', 'Callan', 'Tabb', \"Daniel's\", 'Legislatures', 'erase', 'depositors', 'Gaynor', 'Brady', 'Harlingen', 'Deaf', 'Bexar', 'Tarrant', '$451,500', '$157,460', '$88,000']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hapaxes[ : 50]\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</variable></variables><block type=\"lists_getSublist\" id=\"9xn$*AOGa:EQ*Dc,*!43\" x=\"55\" y=\"244\"><mutation at1=\"false\" at2=\"true\"></mutation><field name=\"WHERE1\">FIRST</field><field name=\"WHERE2\">FROM_START</field><value name=\"LIST\"><block type=\"variables_get\" id=\"bk_U%Y.KPnZ:vC9_me^X\"><field name=\"VAR\" id=\"g/vf{gMn5Uhes:d71L8R\">hapaxes</field></block></value><value name=\"AT2\"><block type=\"math_number\" id=\"f`ceI1r6(p/hz!Su9Vp5\"><field name=\"NUM\">50</field></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these rare words look like they might be important!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "### tf-idf\n",
    "\n",
    "### Text length in characters\n",
    "\n",
    "When we consider text length as a metric, we can clearly consider it on multiple scales.\n",
    "At the coarsest level we can consider the length of the entire text in characters.\n",
    "We've previously seen how to use NLTK to get a list of texts in a corpus and the raw form of the text (i.e. string, or sequence of characters).\n",
    "Let's combine those operations and also get the length of the raw text:\n",
    "\n",
    "- Set rawLengths to a list with one element containing\n",
    "    - for each item `i` in list with `gutenberg` do `fileids` (see LOOPS)\n",
    "        - yield length of (see TEXT) with `gutenberg` do `raw` using `i`\n",
    "- Display rawLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[887071, 466292, 673022, 4332554, 38153, 249439, 84663, 144395, 457450, 406629, 320525, 935158, 1242990, 468220, 112310, 162881, 100351, 711215]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawLengths = [(len(gutenberg.raw(i))) for i in (gutenberg.fileids())]\n",
    "\n",
    "rawLengths\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"AO?GdNQ:*92|iDWB.)YR\">rawLengths</variable><variable id=\"LZ#}.J~9XYczA[nu4?|Q\">i</variable><variable id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</variable></variables><block type=\"variables_set\" id=\"ZR=zxJ`,Px9$cDQ}u?!N\" x=\"29\" y=\"316\"><field name=\"VAR\" id=\"AO?GdNQ:*92|iDWB.)YR\">rawLengths</field><value name=\"VALUE\"><block type=\"lists_create_with\" id=\"8eO0[B%0~mtEmLX:+=dw\"><mutation items=\"1\"></mutation><value name=\"ADD0\"><block type=\"comprehensionForEach\" id=\"qHXxT3|WBM:kMw~muDTN\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field><value name=\"LIST\"><block type=\"varDoMethod\" id=\"tLR@!_zful,@toy1e3E(\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">fileids</field><data>gutenberg:fileids</data></block></value><value name=\"YIELD\"><block type=\"text_length\" id=\"C[M$vurF8L;mQ|g`!((h\"><value name=\"VALUE\"><shadow type=\"text\" id=\"OWYJxoN6q~fXVN0HS0QW\"><field name=\"TEXT\">abc</field></shadow><block type=\"varDoMethod\" id=\"#IalxaHkKH5=q1de@8Ar\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">raw</field><data>gutenberg:raw</data><value name=\"INPUT\"><block type=\"variables_get\" id=\"u[Lug07Y.B({Q]G-6du|\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field></block></value></block></value></block></value></block></value></block></value></block><block type=\"variables_get\" id=\")DU}BKs8923`-}.@eA)Q\" x=\"8\" y=\"402\"><field name=\"VAR\" id=\"AO?GdNQ:*92|iDWB.)YR\">rawLengths</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each one of these is the length (in characters) of a book in the `gutenberg` corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text length in words\n",
    "\n",
    "Let's repeat this operation but retrieve words instead of text length.\n",
    "Since we've already covered how to do word tokenization manually, we'll use the built in `gutenberg` tokenization to focus on the new concept:\n",
    "\n",
    "- Set wordLengths to a list with one element containing\n",
    "    - for each item `i` in list with `gutenberg` do `fileids` (see LOOPS)\n",
    "        - yield length of (see LISTS) with `gutenberg` do `words` using `i`\n",
    "- Display wordLengths\n",
    "\n",
    "Note the only changes are `words` instead of `raw` and `length of` from LISTS instead of TEXT.\n",
    "This is because while `raw` gives us one big string, `words` gives us a list of words.\n",
    "However, the logic of the loop is the same (we sometimes call this a traversal, because we are traversing the data to calculate something)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[192427, 98171, 141576, 1010654, 8354, 55563, 18963, 34110, 96996, 86063, 69213, 210663, 260819, 96825, 25833, 37360, 23140, 154883]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordLengths = [(len(gutenberg.words(i))) for i in (gutenberg.fileids())]\n",
    "\n",
    "wordLengths\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"nb}L;_W{,H)*Jc!qq]@S\">wordLengths</variable><variable id=\"LZ#}.J~9XYczA[nu4?|Q\">i</variable><variable id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</variable></variables><block type=\"variables_set\" id=\"SKZpRLP{wcl/g*{^W3WV\" x=\"4\" y=\"319\"><field name=\"VAR\" id=\"nb}L;_W{,H)*Jc!qq]@S\">wordLengths</field><value name=\"VALUE\"><block type=\"lists_create_with\" id=\"8eO0[B%0~mtEmLX:+=dw\"><mutation items=\"1\"></mutation><value name=\"ADD0\"><block type=\"comprehensionForEach\" id=\"qHXxT3|WBM:kMw~muDTN\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field><value name=\"LIST\"><block type=\"varDoMethod\" id=\"tLR@!_zful,@toy1e3E(\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">fileids</field><data>gutenberg:fileids</data></block></value><value name=\"YIELD\"><block type=\"lists_length\" id=\"b5(0SiwR87=9]SU8IBvy\"><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"#IalxaHkKH5=q1de@8Ar\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">words</field><data>gutenberg:words</data><value name=\"INPUT\"><block type=\"variables_get\" id=\"u[Lug07Y.B({Q]G-6du|\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field></block></value></block></value></block></value></block></value></block></value></block><block type=\"variables_get\" id=\"aJWMl/VaGmo=-c|`$nxp\" x=\"8\" y=\"436\"><field name=\"VAR\" id=\"nb}L;_W{,H)*Jc!qq]@S\">wordLengths</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the number or words is much shorter than the number of characters.\n",
    "We will return to this shortly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text length in sentences\n",
    "\n",
    "Let's look at the same text, but this time in sentences:\n",
    "\n",
    "- Set sentenceLengths to a list with one element containing\n",
    "    - for each item `i` in list with `gutenberg` do `fileids` (see LOOPS)\n",
    "        - yield length of (see LISTS) with `gutenberg` do `sents` using `i`\n",
    "- Display sentenceLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7752, 3747, 4999, 30103, 438, 2863, 1054, 1703, 4779, 3806, 3742, 10230, 10059, 1851, 2163, 3106, 1907, 4250]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceLengths = [(len(gutenberg.sents(i))) for i in (gutenberg.fileids())]\n",
    "\n",
    "sentenceLengths\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"$OD[:+1843Cn0O3j8JiE\">sentenceLengths</variable><variable id=\"LZ#}.J~9XYczA[nu4?|Q\">i</variable><variable id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</variable></variables><block type=\"variables_set\" id=\"SKZpRLP{wcl/g*{^W3WV\" x=\"4\" y=\"319\"><field name=\"VAR\" id=\"$OD[:+1843Cn0O3j8JiE\">sentenceLengths</field><value name=\"VALUE\"><block type=\"lists_create_with\" id=\"8eO0[B%0~mtEmLX:+=dw\"><mutation items=\"1\"></mutation><value name=\"ADD0\"><block type=\"comprehensionForEach\" id=\"qHXxT3|WBM:kMw~muDTN\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field><value name=\"LIST\"><block type=\"varDoMethod\" id=\"tLR@!_zful,@toy1e3E(\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">fileids</field><data>gutenberg:fileids</data></block></value><value name=\"YIELD\"><block type=\"lists_length\" id=\"b5(0SiwR87=9]SU8IBvy\"><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"#IalxaHkKH5=q1de@8Ar\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">sents</field><data>gutenberg:sents</data><value name=\"INPUT\"><block type=\"variables_get\" id=\"u[Lug07Y.B({Q]G-6du|\"><field name=\"VAR\" id=\"LZ#}.J~9XYczA[nu4?|Q\">i</field></block></value></block></value></block></value></block></value></block></value></block><block type=\"variables_get\" id=\"aJWMl/VaGmo=-c|`$nxp\" x=\"8\" y=\"436\"><field name=\"VAR\" id=\"$OD[:+1843Cn0O3j8JiE\">sentenceLengths</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again, the number of sentences is quite a bit lower than the number of words, as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average word/sentence length\n",
    "\n",
    "There are at least two ways we could calculate average word length using what we've covered so far.\n",
    "We could to a traversal of words and calculate the average word length for each text.\n",
    "Alternatively, we could use the values we've already compute and divide.\n",
    "The same applies to sentence length.\n",
    "\n",
    "Conceptually what we want to do is perform operations with the first element of `wordLengths`, `sentenceLengths`, and `rawLengths`, the second element of these lists, and so on.\n",
    "Rather than create our own data structures for facilitating these operations, let's put these lists into a dataframe.\n",
    "Start by importing `pandas`:\n",
    "\n",
    "- import `pandas` as `pd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"_V`RIwppcpbRKT:m6^qH\">pd</variable></variables><block type=\"importAs\" id=\"Gy5)p-`[BHUUWE}k1DeL\" x=\"16\" y=\"10\"><field name=\"libraryName\">pandas</field><field name=\"libraryAlias\" id=\"_V`RIwppcpbRKT:m6^qH\">pd</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to create a dataframe with these lists using the `zip` operator in LISTS:\n",
    "\n",
    "- Set `dataframe` to with `pd` create `DataFrame` using a list containing\n",
    "    - `zip` a list containing\n",
    "        - with `gutenberg` do `fileids`,`wordLengths`, `sentenceLengths`, `rawLengths`\n",
    "    - freestyle `columns=['corpus','words','sentences','characters']`\n",
    "- Display `dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>characters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austen-emma.txt</td>\n",
       "      <td>192427</td>\n",
       "      <td>7752</td>\n",
       "      <td>887071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>austen-persuasion.txt</td>\n",
       "      <td>98171</td>\n",
       "      <td>3747</td>\n",
       "      <td>466292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>141576</td>\n",
       "      <td>4999</td>\n",
       "      <td>673022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bible-kjv.txt</td>\n",
       "      <td>1010654</td>\n",
       "      <td>30103</td>\n",
       "      <td>4332554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blake-poems.txt</td>\n",
       "      <td>8354</td>\n",
       "      <td>438</td>\n",
       "      <td>38153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bryant-stories.txt</td>\n",
       "      <td>55563</td>\n",
       "      <td>2863</td>\n",
       "      <td>249439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burgess-busterbrown.txt</td>\n",
       "      <td>18963</td>\n",
       "      <td>1054</td>\n",
       "      <td>84663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>carroll-alice.txt</td>\n",
       "      <td>34110</td>\n",
       "      <td>1703</td>\n",
       "      <td>144395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chesterton-ball.txt</td>\n",
       "      <td>96996</td>\n",
       "      <td>4779</td>\n",
       "      <td>457450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chesterton-brown.txt</td>\n",
       "      <td>86063</td>\n",
       "      <td>3806</td>\n",
       "      <td>406629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterton-thursday.txt</td>\n",
       "      <td>69213</td>\n",
       "      <td>3742</td>\n",
       "      <td>320525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edgeworth-parents.txt</td>\n",
       "      <td>210663</td>\n",
       "      <td>10230</td>\n",
       "      <td>935158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>260819</td>\n",
       "      <td>10059</td>\n",
       "      <td>1242990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton-paradise.txt</td>\n",
       "      <td>96825</td>\n",
       "      <td>1851</td>\n",
       "      <td>468220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shakespeare-caesar.txt</td>\n",
       "      <td>25833</td>\n",
       "      <td>2163</td>\n",
       "      <td>112310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shakespeare-hamlet.txt</td>\n",
       "      <td>37360</td>\n",
       "      <td>3106</td>\n",
       "      <td>162881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shakespeare-macbeth.txt</td>\n",
       "      <td>23140</td>\n",
       "      <td>1907</td>\n",
       "      <td>100351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>whitman-leaves.txt</td>\n",
       "      <td>154883</td>\n",
       "      <td>4250</td>\n",
       "      <td>711215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "None"
      ],
      "text/plain": [
       "                     corpus    words  sentences  characters\n",
       "0           austen-emma.txt   192427       7752      887071\n",
       "1     austen-persuasion.txt    98171       3747      466292\n",
       "2          austen-sense.txt   141576       4999      673022\n",
       "3             bible-kjv.txt  1010654      30103     4332554\n",
       "4           blake-poems.txt     8354        438       38153\n",
       "5        bryant-stories.txt    55563       2863      249439\n",
       "6   burgess-busterbrown.txt    18963       1054       84663\n",
       "7         carroll-alice.txt    34110       1703      144395\n",
       "8       chesterton-ball.txt    96996       4779      457450\n",
       "9      chesterton-brown.txt    86063       3806      406629\n",
       "10  chesterton-thursday.txt    69213       3742      320525\n",
       "11    edgeworth-parents.txt   210663      10230      935158\n",
       "12   melville-moby_dick.txt   260819      10059     1242990\n",
       "13      milton-paradise.txt    96825       1851      468220\n",
       "14   shakespeare-caesar.txt    25833       2163      112310\n",
       "15   shakespeare-hamlet.txt    37360       3106      162881\n",
       "16  shakespeare-macbeth.txt    23140       1907      100351\n",
       "17       whitman-leaves.txt   154883       4250      711215"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(zip(gutenberg.fileids(), wordLengths, sentenceLengths, rawLengths), columns=['corpus','words','sentences','characters'])\n",
    "\n",
    "dataframe\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</variable><variable id=\"_V`RIwppcpbRKT:m6^qH\">pd</variable><variable id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</variable><variable id=\"nb}L;_W{,H)*Jc!qq]@S\">wordLengths</variable><variable id=\"$OD[:+1843Cn0O3j8JiE\">sentenceLengths</variable><variable id=\"AO?GdNQ:*92|iDWB.)YR\">rawLengths</variable></variables><block type=\"variables_set\" id=\"Nnj3jwtJa6+~cV1=RDn_\" x=\"-149\" y=\"237\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"VALUE\"><block type=\"varCreateObject\" id=\"*C0V~q-fS]kDUMRq`O-N\"><field name=\"VAR\" id=\"_V`RIwppcpbRKT:m6^qH\">pd</field><field name=\"MEMBER\">DataFrame</field><data>pd:DataFrame</data><value name=\"INPUT\"><block type=\"lists_create_with\" id=\"DoM~-@qI)6TgbDc;vBMb\"><mutation items=\"2\"></mutation><value name=\"ADD0\"><block type=\"zipBlock\" id=\"nv7/65]-+;=,M.B)yU%U\"><value name=\"x\"><block type=\"lists_create_with\" id=\"@PN$;KCRy[Jv;QJ+d#($\"><mutation items=\"4\"></mutation><value name=\"ADD0\"><block type=\"varDoMethod\" id=\"FJ#DraHg!(/g)_[-^Dn]\"><field name=\"VAR\" id=\"`$^y`^v4:G8DO1QCBCw8\">gutenberg</field><field name=\"MEMBER\">fileids</field><data>gutenberg:fileids</data></block></value><value name=\"ADD1\"><block type=\"variables_get\" id=\"1UbO_xg6I)qqO#p=]Trh\"><field name=\"VAR\" id=\"nb}L;_W{,H)*Jc!qq]@S\">wordLengths</field></block></value><value name=\"ADD2\"><block type=\"variables_get\" id=\"%~eQRKbkLX{by+raZ$LQ\"><field name=\"VAR\" id=\"$OD[:+1843Cn0O3j8JiE\">sentenceLengths</field></block></value><value name=\"ADD3\"><block type=\"variables_get\" id=\"}U=.2[w^C@TMLrYf)B-o\"><field name=\"VAR\" id=\"AO?GdNQ:*92|iDWB.)YR\">rawLengths</field></block></value></block></value></block></value><value name=\"ADD1\"><block type=\"dummyOutputCodeBlock\" id=\"o35uqta54?^UVk|[,.|(\"><field name=\"CODE\">columns=['corpus','words','sentences','characters']</field></block></value></block></value></block></value></block><block type=\"variables_get\" id=\"(gZ^x=Q!@}~:|xjc+ZXy\" x=\"-133\" y=\"397\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This nicely brings together and displays everything we've done so far.\n",
    "\n",
    "To calculate average word length and sentence length, just add columns:\n",
    "\n",
    "- set `dataframe` to with `dataframe` to `assign` using\n",
    "    - freestyle `avg_wl =` `dataframe[\"characters\"]` / `dataframe[\"words\"]`\n",
    "- set `dataframe` to with `dataframe` to `assign` using\n",
    "    - freestyle `avg_sl =` `dataframe[\"words\"]` / `dataframe[\"sentences\"]`\n",
    "- Display dataframe\n",
    "\n",
    "Note that the standard unit for word length is characters but that the standard unit for sentence length is words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>characters</th>\n",
       "      <th>avg_wl</th>\n",
       "      <th>avg_sl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austen-emma.txt</td>\n",
       "      <td>192427</td>\n",
       "      <td>7752</td>\n",
       "      <td>887071</td>\n",
       "      <td>4.609909</td>\n",
       "      <td>24.822884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>austen-persuasion.txt</td>\n",
       "      <td>98171</td>\n",
       "      <td>3747</td>\n",
       "      <td>466292</td>\n",
       "      <td>4.749794</td>\n",
       "      <td>26.199893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>141576</td>\n",
       "      <td>4999</td>\n",
       "      <td>673022</td>\n",
       "      <td>4.753786</td>\n",
       "      <td>28.320864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bible-kjv.txt</td>\n",
       "      <td>1010654</td>\n",
       "      <td>30103</td>\n",
       "      <td>4332554</td>\n",
       "      <td>4.286882</td>\n",
       "      <td>33.573199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blake-poems.txt</td>\n",
       "      <td>8354</td>\n",
       "      <td>438</td>\n",
       "      <td>38153</td>\n",
       "      <td>4.567034</td>\n",
       "      <td>19.073059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bryant-stories.txt</td>\n",
       "      <td>55563</td>\n",
       "      <td>2863</td>\n",
       "      <td>249439</td>\n",
       "      <td>4.489300</td>\n",
       "      <td>19.407265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burgess-busterbrown.txt</td>\n",
       "      <td>18963</td>\n",
       "      <td>1054</td>\n",
       "      <td>84663</td>\n",
       "      <td>4.464642</td>\n",
       "      <td>17.991461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>carroll-alice.txt</td>\n",
       "      <td>34110</td>\n",
       "      <td>1703</td>\n",
       "      <td>144395</td>\n",
       "      <td>4.233216</td>\n",
       "      <td>20.029360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chesterton-ball.txt</td>\n",
       "      <td>96996</td>\n",
       "      <td>4779</td>\n",
       "      <td>457450</td>\n",
       "      <td>4.716174</td>\n",
       "      <td>20.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chesterton-brown.txt</td>\n",
       "      <td>86063</td>\n",
       "      <td>3806</td>\n",
       "      <td>406629</td>\n",
       "      <td>4.724783</td>\n",
       "      <td>22.612454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterton-thursday.txt</td>\n",
       "      <td>69213</td>\n",
       "      <td>3742</td>\n",
       "      <td>320525</td>\n",
       "      <td>4.630994</td>\n",
       "      <td>18.496259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edgeworth-parents.txt</td>\n",
       "      <td>210663</td>\n",
       "      <td>10230</td>\n",
       "      <td>935158</td>\n",
       "      <td>4.439118</td>\n",
       "      <td>20.592669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>260819</td>\n",
       "      <td>10059</td>\n",
       "      <td>1242990</td>\n",
       "      <td>4.765719</td>\n",
       "      <td>25.928919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton-paradise.txt</td>\n",
       "      <td>96825</td>\n",
       "      <td>1851</td>\n",
       "      <td>468220</td>\n",
       "      <td>4.835735</td>\n",
       "      <td>52.309562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shakespeare-caesar.txt</td>\n",
       "      <td>25833</td>\n",
       "      <td>2163</td>\n",
       "      <td>112310</td>\n",
       "      <td>4.347540</td>\n",
       "      <td>11.943135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shakespeare-hamlet.txt</td>\n",
       "      <td>37360</td>\n",
       "      <td>3106</td>\n",
       "      <td>162881</td>\n",
       "      <td>4.359770</td>\n",
       "      <td>12.028332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shakespeare-macbeth.txt</td>\n",
       "      <td>23140</td>\n",
       "      <td>1907</td>\n",
       "      <td>100351</td>\n",
       "      <td>4.336690</td>\n",
       "      <td>12.134242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>whitman-leaves.txt</td>\n",
       "      <td>154883</td>\n",
       "      <td>4250</td>\n",
       "      <td>711215</td>\n",
       "      <td>4.591950</td>\n",
       "      <td>36.443059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "None"
      ],
      "text/plain": [
       "                     corpus    words  ...    avg_wl     avg_sl\n",
       "0           austen-emma.txt   192427  ...  4.609909  24.822884\n",
       "1     austen-persuasion.txt    98171  ...  4.749794  26.199893\n",
       "2          austen-sense.txt   141576  ...  4.753786  28.320864\n",
       "3             bible-kjv.txt  1010654  ...  4.286882  33.573199\n",
       "4           blake-poems.txt     8354  ...  4.567034  19.073059\n",
       "5        bryant-stories.txt    55563  ...  4.489300  19.407265\n",
       "6   burgess-busterbrown.txt    18963  ...  4.464642  17.991461\n",
       "7         carroll-alice.txt    34110  ...  4.233216  20.029360\n",
       "8       chesterton-ball.txt    96996  ...  4.716174  20.296296\n",
       "9      chesterton-brown.txt    86063  ...  4.724783  22.612454\n",
       "10  chesterton-thursday.txt    69213  ...  4.630994  18.496259\n",
       "11    edgeworth-parents.txt   210663  ...  4.439118  20.592669\n",
       "12   melville-moby_dick.txt   260819  ...  4.765719  25.928919\n",
       "13      milton-paradise.txt    96825  ...  4.835735  52.309562\n",
       "14   shakespeare-caesar.txt    25833  ...  4.347540  11.943135\n",
       "15   shakespeare-hamlet.txt    37360  ...  4.359770  12.028332\n",
       "16  shakespeare-macbeth.txt    23140  ...  4.336690  12.134242\n",
       "17       whitman-leaves.txt   154883  ...  4.591950  36.443059\n",
       "\n",
       "[18 rows x 6 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.assign(avg_wl= (dataframe['characters'] / dataframe['words']))\n",
    "dataframe = dataframe.assign(avg_sl= (dataframe['words'] / dataframe['sentences']))\n",
    "\n",
    "dataframe\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</variable></variables><block type=\"variables_set\" id=\"{UO)w}M?tYx?A02OPAw9\" x=\"-83\" y=\"249\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"L%G*;r8*$i5SLn{,Cc$T\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><field name=\"MEMBER\">assign</field><data>dataframe:assign</data><value name=\"INPUT\"><block type=\"valueOutputCodeBlock\" id=\"Ux2OR.~,)cCrIxgQW6VI\"><field name=\"CODE\">avg_wl=</field><value name=\"INPUT\"><block type=\"math_arithmetic\" id=\"^JEFtmhs2.cv#;80c/nT\"><field name=\"OP\">DIVIDE</field><value name=\"A\"><shadow type=\"math_number\" id=\"syWxT)`[^TBT:IsIQGMf\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"5zNI-WP@PpW0doRlek8W\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"3@IMZDY0GOmgS:YQgx?C\"><field name=\"TEXT\">characters</field></block></value></block></value><value name=\"B\"><shadow type=\"math_number\" id=\"t1.s:%LN=uK/vv%zl:f:\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"QeW+!Bpy|dosxiHiI(Vq\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"sg3+/)wO!$kLNdtDKOJN\"><field name=\"TEXT\">words</field></block></value></block></value></block></value></block></value></block></value><next><block type=\"variables_set\" id=\";EOx!PoNSJEXe3}Nc1AU\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"-{X4*i^Z:O4lkNW=F]rs\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><field name=\"MEMBER\">assign</field><data>dataframe:assign</data><value name=\"INPUT\"><block type=\"valueOutputCodeBlock\" id=\"P+/y;r)NaM2k#OEIf08~\"><field name=\"CODE\">avg_sl=</field><value name=\"INPUT\"><block type=\"math_arithmetic\" id=\"Xl4rhP=?Xbe$O90]f;b1\"><field name=\"OP\">DIVIDE</field><value name=\"A\"><shadow type=\"math_number\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"fp`q$osSW7CCT3EC^-jh\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"M/QDQE2#j$}uzL!/L{ow\"><field name=\"TEXT\">words</field></block></value></block></value><value name=\"B\"><shadow type=\"math_number\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"u.cc%cZ]S6NC+|6@7MZc\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"FaX@#$GZ_F/S]$=oXR@?\"><field name=\"TEXT\">sentences</field></block></value></block></value></block></value></block></value></block></value></block></next></block><block type=\"variables_get\" id=\"uzxkeHUiih]mUfldHAMe\" x=\"-98\" y=\"405\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readability\n",
    "\n",
    "What we've calculated so far may seem simplistic and perhaps not that useful.\n",
    "However, several of these metrics are components of perhaps the most well known readability formula, [Flesch Kincaid Grade Level (FKGL)](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests):\n",
    "\n",
    "\\begin{equation*}\n",
    "0.39 \\left( \\frac{\\mbox{total words}}{\\mbox{total sentences}} \\right) +11.8 \\left( \\frac{\\mbox{total syllables}}{\\mbox{total words}} \\right) - 15.59\n",
    "\\end{equation*}\n",
    "\n",
    "FKGL gives us a sense of how difficult text is to read, which could be an important/useful predictor as well as an interesting descriptive statistic.\n",
    "\n",
    "We don't have syllable length, however.\n",
    "Syllable length is a bit of a pain to calculate because English has a deep orthography, so the best way is to use a pronunciation dictionary like [this](https://github.com/steveash/jg2p).\n",
    "For now, we will just assume that English has 1.5 syllables per word and estimate this component:\n",
    "\n",
    "- set `dataframe` to with `dataframe` to `assign` using\n",
    "    - freestyle `fkgl =` 0.39 * `dataframe[\"words\"]` / `dataframe[\"sentences\"]` + 11.8 * 1.5 - 15.59\n",
    "- Display dataframe\n",
    "\n",
    "*Note 1.5 * words/words = 1.5*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>words</th>\n",
       "      <th>sentences</th>\n",
       "      <th>characters</th>\n",
       "      <th>avg_wl</th>\n",
       "      <th>avg_sl</th>\n",
       "      <th>fkgl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>austen-emma.txt</td>\n",
       "      <td>192427</td>\n",
       "      <td>7752</td>\n",
       "      <td>887071</td>\n",
       "      <td>4.609909</td>\n",
       "      <td>24.822884</td>\n",
       "      <td>11.790925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>austen-persuasion.txt</td>\n",
       "      <td>98171</td>\n",
       "      <td>3747</td>\n",
       "      <td>466292</td>\n",
       "      <td>4.749794</td>\n",
       "      <td>26.199893</td>\n",
       "      <td>12.327958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>austen-sense.txt</td>\n",
       "      <td>141576</td>\n",
       "      <td>4999</td>\n",
       "      <td>673022</td>\n",
       "      <td>4.753786</td>\n",
       "      <td>28.320864</td>\n",
       "      <td>13.155137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bible-kjv.txt</td>\n",
       "      <td>1010654</td>\n",
       "      <td>30103</td>\n",
       "      <td>4332554</td>\n",
       "      <td>4.286882</td>\n",
       "      <td>33.573199</td>\n",
       "      <td>15.203547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blake-poems.txt</td>\n",
       "      <td>8354</td>\n",
       "      <td>438</td>\n",
       "      <td>38153</td>\n",
       "      <td>4.567034</td>\n",
       "      <td>19.073059</td>\n",
       "      <td>9.548493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bryant-stories.txt</td>\n",
       "      <td>55563</td>\n",
       "      <td>2863</td>\n",
       "      <td>249439</td>\n",
       "      <td>4.489300</td>\n",
       "      <td>19.407265</td>\n",
       "      <td>9.678833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>burgess-busterbrown.txt</td>\n",
       "      <td>18963</td>\n",
       "      <td>1054</td>\n",
       "      <td>84663</td>\n",
       "      <td>4.464642</td>\n",
       "      <td>17.991461</td>\n",
       "      <td>9.126670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>carroll-alice.txt</td>\n",
       "      <td>34110</td>\n",
       "      <td>1703</td>\n",
       "      <td>144395</td>\n",
       "      <td>4.233216</td>\n",
       "      <td>20.029360</td>\n",
       "      <td>9.921450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chesterton-ball.txt</td>\n",
       "      <td>96996</td>\n",
       "      <td>4779</td>\n",
       "      <td>457450</td>\n",
       "      <td>4.716174</td>\n",
       "      <td>20.296296</td>\n",
       "      <td>10.025556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chesterton-brown.txt</td>\n",
       "      <td>86063</td>\n",
       "      <td>3806</td>\n",
       "      <td>406629</td>\n",
       "      <td>4.724783</td>\n",
       "      <td>22.612454</td>\n",
       "      <td>10.928857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chesterton-thursday.txt</td>\n",
       "      <td>69213</td>\n",
       "      <td>3742</td>\n",
       "      <td>320525</td>\n",
       "      <td>4.630994</td>\n",
       "      <td>18.496259</td>\n",
       "      <td>9.323541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>edgeworth-parents.txt</td>\n",
       "      <td>210663</td>\n",
       "      <td>10230</td>\n",
       "      <td>935158</td>\n",
       "      <td>4.439118</td>\n",
       "      <td>20.592669</td>\n",
       "      <td>10.141141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>melville-moby_dick.txt</td>\n",
       "      <td>260819</td>\n",
       "      <td>10059</td>\n",
       "      <td>1242990</td>\n",
       "      <td>4.765719</td>\n",
       "      <td>25.928919</td>\n",
       "      <td>12.222279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>milton-paradise.txt</td>\n",
       "      <td>96825</td>\n",
       "      <td>1851</td>\n",
       "      <td>468220</td>\n",
       "      <td>4.835735</td>\n",
       "      <td>52.309562</td>\n",
       "      <td>22.510729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>shakespeare-caesar.txt</td>\n",
       "      <td>25833</td>\n",
       "      <td>2163</td>\n",
       "      <td>112310</td>\n",
       "      <td>4.347540</td>\n",
       "      <td>11.943135</td>\n",
       "      <td>6.767822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>shakespeare-hamlet.txt</td>\n",
       "      <td>37360</td>\n",
       "      <td>3106</td>\n",
       "      <td>162881</td>\n",
       "      <td>4.359770</td>\n",
       "      <td>12.028332</td>\n",
       "      <td>6.801050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shakespeare-macbeth.txt</td>\n",
       "      <td>23140</td>\n",
       "      <td>1907</td>\n",
       "      <td>100351</td>\n",
       "      <td>4.336690</td>\n",
       "      <td>12.134242</td>\n",
       "      <td>6.842354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>whitman-leaves.txt</td>\n",
       "      <td>154883</td>\n",
       "      <td>4250</td>\n",
       "      <td>711215</td>\n",
       "      <td>4.591950</td>\n",
       "      <td>36.443059</td>\n",
       "      <td>16.322793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "None"
      ],
      "text/plain": [
       "                     corpus    words  sentences  ...    avg_wl     avg_sl       fkgl\n",
       "0           austen-emma.txt   192427       7752  ...  4.609909  24.822884  11.790925\n",
       "1     austen-persuasion.txt    98171       3747  ...  4.749794  26.199893  12.327958\n",
       "2          austen-sense.txt   141576       4999  ...  4.753786  28.320864  13.155137\n",
       "3             bible-kjv.txt  1010654      30103  ...  4.286882  33.573199  15.203547\n",
       "4           blake-poems.txt     8354        438  ...  4.567034  19.073059   9.548493\n",
       "5        bryant-stories.txt    55563       2863  ...  4.489300  19.407265   9.678833\n",
       "6   burgess-busterbrown.txt    18963       1054  ...  4.464642  17.991461   9.126670\n",
       "7         carroll-alice.txt    34110       1703  ...  4.233216  20.029360   9.921450\n",
       "8       chesterton-ball.txt    96996       4779  ...  4.716174  20.296296  10.025556\n",
       "9      chesterton-brown.txt    86063       3806  ...  4.724783  22.612454  10.928857\n",
       "10  chesterton-thursday.txt    69213       3742  ...  4.630994  18.496259   9.323541\n",
       "11    edgeworth-parents.txt   210663      10230  ...  4.439118  20.592669  10.141141\n",
       "12   melville-moby_dick.txt   260819      10059  ...  4.765719  25.928919  12.222279\n",
       "13      milton-paradise.txt    96825       1851  ...  4.835735  52.309562  22.510729\n",
       "14   shakespeare-caesar.txt    25833       2163  ...  4.347540  11.943135   6.767822\n",
       "15   shakespeare-hamlet.txt    37360       3106  ...  4.359770  12.028332   6.801050\n",
       "16  shakespeare-macbeth.txt    23140       1907  ...  4.336690  12.134242   6.842354\n",
       "17       whitman-leaves.txt   154883       4250  ...  4.591950  36.443059  16.322793\n",
       "\n",
       "[18 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = dataframe.assign(fkgl= ((0.39 * (dataframe['words'] / dataframe['sentences']) + 11.8 * 1.5) - 15.59))\n",
    "\n",
    "dataframe\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</variable></variables><block type=\"variables_set\" id=\"d3ELqhcW@UA^R%PLy3cV\" x=\"-83\" y=\"308\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"!?g`gMP):imN8F)T,@V|\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><field name=\"MEMBER\">assign</field><data>dataframe:assign</data><value name=\"INPUT\"><block type=\"valueOutputCodeBlock\" id=\"k^_3ol/yS5*#Dha3rPVq\"><field name=\"CODE\">fkgl=</field><value name=\"INPUT\"><block type=\"math_arithmetic\" id=\"Md5u*{OHNtri0AjDj],6\"><field name=\"OP\">MINUS</field><value name=\"A\"><shadow type=\"math_number\" id=\"oOOHvHpa1xT0^Jls*1X+\"><field name=\"NUM\">0.39</field></shadow><block type=\"math_arithmetic\" id=\"QGJQ@m3mx5!l=,g9-R+d\"><field name=\"OP\">ADD</field><value name=\"A\"><shadow type=\"math_number\" id=\"X]w:+`6NY)?+=r#3v?Aj\"><field name=\"NUM\">0.39</field></shadow><block type=\"math_arithmetic\" id=\",gsasO{}sRYc]60t@#ud\"><field name=\"OP\">MULTIPLY</field><value name=\"A\"><shadow type=\"math_number\" id=\"^KWa~qEgh3Q5R?==H)+9\"><field name=\"NUM\">0.39</field></shadow></value><value name=\"B\"><shadow type=\"math_number\" id=\"?4DQu[d7x;oy^4iY|Y3(\"><field name=\"NUM\">1</field></shadow><block type=\"math_arithmetic\" id=\"b1}M?uM#pV~iqEz`%Dh~\"><field name=\"OP\">DIVIDE</field><value name=\"A\"><shadow type=\"math_number\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"/t1A;EYsDfw+BYK-f{P8\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"/`cSF)tsx%3]HefEnKlV\"><field name=\"TEXT\">words</field></block></value></block></value><value name=\"B\"><shadow type=\"math_number\"><field name=\"NUM\">1</field></shadow><block type=\"indexer\" id=\"9_HN7=?;UGbK`ZFpBD)n\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field><value name=\"INDEX\"><block type=\"text\" id=\"SDk,ItV,c;N.~+Z%vOH]\"><field name=\"TEXT\">sentences</field></block></value></block></value></block></value></block></value><value name=\"B\"><shadow type=\"math_number\" id=\"osy!WzPZ^Ac.Li?,M]Sq\"><field name=\"NUM\">1</field></shadow><block type=\"math_arithmetic\" id=\"pns2jEFkEFV2potV{wzJ\"><field name=\"OP\">MULTIPLY</field><value name=\"A\"><shadow type=\"math_number\" id=\"~z95el]}Uct`QV~*3@LC\"><field name=\"NUM\">11.8</field></shadow></value><value name=\"B\"><shadow type=\"math_number\" id=\"L,wO%x|x/NAv$%-5KtZc\"><field name=\"NUM\">1.5</field></shadow></value></block></value></block></value><value name=\"B\"><shadow type=\"math_number\" id=\"N6x=21,Sww{nHR%@JF|@\"><field name=\"NUM\">15.59</field></shadow></value></block></value></block></value></block></value></block><block type=\"variables_get\" id=\"F^RD,W:_|bYpb/e8Wq3b\" x=\"-90\" y=\"410\"><field name=\"VAR\" id=\"d*P53^Ni!VyA[RubgfYr\">dataframe</field></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The readability differences generally make sense - `Alice and Wonderland` lower than the `King James Bible` lower than `Paradise Lost`, but we also see Shakespeare is the least difficult.\n",
    "This is perhaps expected given the formula, since Shakespeare has the lowest `avg_sl`, but seems intuitively incorrect for those who have experienced Shakespeare. \n",
    "Note however, that FKGL does not take into account the frequency of the words themselves (how rare they are), which is a question of *distribution*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution-based metrics \n",
    "\n",
    "### Type/token ratio\n",
    "\n",
    "### Frequency distributions\n",
    "\n",
    "### Conditional distributions\n",
    "\n",
    "### Vectorization\n",
    "\n",
    "### tf-idf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
